{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a1baf-24b9-434a-bbcd-c0cdc05bf41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from description_generator_helper import custom_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7263079d-01c2-4b09-b7b3-bc0354fc3f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the metadata\n",
    "directory = r\"D:\\LLM_Project\\Multimodel Chatbot\\Data\\train\"\n",
    "master_csv_file_path = os.path.join(directory, \"master_csv.csv\")\n",
    "master_df = pd.read_csv(master_csv_file_path, dtype={\"image_id\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7b74d8-903f-402d-8753-4e917ecdc47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the multimodal reasoning model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    model_name, torch_dtype=\"auto\", \n",
    ").to(device)\n",
    "model.eval()\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df21ec79-a80f-4983-87fe-6f41362ba99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prmpt = custom_prompt(model, processor, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc8e309-a0d9-42d4-adb1-3e7b5d4e354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating description and attributes of each image for a better embedding\n",
    "all_descriptions = []\n",
    "all_attributes = []\n",
    "\n",
    "for idx, row in tqdm(master_df.iterrows(), total=len(master_df)):\n",
    "    image_id = row['image_id']\n",
    "    item_id = row['item_id']\n",
    "    \n",
    "    image_directory = r\"D:\\LLM_Project\\Multimodel Chatbot\\Data\\train\\cropped_image_unique\"\n",
    "    retreival_path = os.path.join(image_directory, f\"{image_id}_{item_id}.jpg\")\n",
    "    image = Image.open(retreival_path).convert(\"RGB\")\n",
    "    \n",
    "    description_text = custom_prmpt.description_of_image(image)\n",
    "    all_descriptions.append(description_text[0])\n",
    "\n",
    "    attributes = custom_prmpt.attributes_of_image(description_text[0])\n",
    "    all_attributes.append(attributes)\n",
    "\n",
    "master_df[\"description\"] = all_descriptions\n",
    "master_df[\"attributes\"] = all_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac547f-6387-41c0-8c58-959dff8e74cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the DataFrame as a new metadata\n",
    "master_df.to_csv(r\"D:\\LLM_Project\\Multimodel Chatbot\\Data\\train\\new_master_csv.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2509ded-409b-4671-ae7b-684691b828b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_MM_chatbot_env_3",
   "language": "python",
   "name": "project_mm_chatbot_env_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
